import json
import time
import random
import math
from zai import ZhipuAiClient
import os
import pickle
import numpy as np
import os
from attention_utils import compute_traj_attention, build_attn_dsl_block

os.environ["http_proxy"] = "http://localhost:7890"
os.environ["https_proxy"] = "http://localhost:7890"
# å®šä¹‰é—®é¢˜
DEBATE_QUESTION = "å¦‚ä½•è¯„ä»·æ— äººæœºé›†ç¾¤çš„é£è¡Œè½¨è¿¹ä¼˜åŒ–å’ŒååŒä½œä¸šèƒ½åŠ›ï¼Ÿ"

# è¯„åˆ†æ ‡å‡†é…ç½®
SCORING_CRITERIA = {
    "flight_control": {
        "name": "è½¨è¿¹è¯„ä¼°è¯„åˆ†",
        "weight": 0.0,
        "disabled": True,
        "metrics": {
            "heading_smoothness": {"weight": 0.35, "name": "èˆªå‘å¹³æ»‘åº¦"},
            "path_efficiency": {"weight": 0.30, "name": "è·¯å¾„æ•ˆç‡"},
            "sharp_turn_ratio": {"weight": 0.20, "name": "æ€¥è½¬æ¯”ä¾‹(è¶Šä½è¶Šå¥½)"},
            "altitude_variation": {"weight": 0.15, "name": "é«˜åº¦æ³¢åŠ¨(è¶Šä½è¶Šå¥½)"}
        }
    },
    "swarm_coordination": {
        "name": "å†³ç­–ä¸ååŒè¯„åˆ†",
        "weight": 0.4,
        "metrics": {
            "formation_stability": {"weight": 0.3, "name": "ç¼–é˜Ÿç¨³å®šæ€§"},
            "communication_quality": {"weight": 0.25, "name": "é€šä¿¡è´¨é‡"},
            "coordination_delay": {"weight": 0.25, "name": "åè°ƒå»¶è¿Ÿ"},
            "task_completion": {"weight": 0.2, "name": "ä»»åŠ¡å®Œæˆåº¦"}
        }
    },
    "safety_assessment": {
        "name": "å®‰å…¨è¯„ä¼°è¯„åˆ†",
        "weight": 0.0,
        "metrics": {
            "collision_avoidance": {"weight": 0.4, "name": "é¿ç¢°èƒ½åŠ›"},
            "emergency_response": {"weight": 0.3, "name": "åº”æ€¥å“åº”"},
            "risk_management": {"weight": 0.3, "name": "é£é™©ç®¡æ§"}
        }
    }
}

# è¾…åŠ©ï¼šæ–¹å‘å­—ç¬¦ä¸²
COMPASS_DIRS = [
    ("N", 0), ("NNE", 22.5), ("NE", 45), ("ENE", 67.5),
    ("E", 90), ("ESE", 112.5), ("SE", 135), ("SSE", 157.5),
    ("S", 180), ("SSW", 202.5), ("SW", 225), ("WSW", 247.5),
    ("W", 270), ("WNW", 292.5), ("NW", 315), ("NNW", 337.5)
]


# è‡ªåŠ¨è¯„åˆ†ç®—æ³•
def calculate_flight_scores(flight_data):
    """
    åŸºäºé£è¡Œæ•°æ®è®¡ç®—å„é¡¹è¯„åˆ†
    """
    scores = {}
    
    # 1. é£è¡Œæ§åˆ¶è¯„åˆ†
    flight_control_scores = {}
    
    # è½¨è¿¹å¹³æ»‘åº¦è¯„åˆ† (åŸºäºé€Ÿåº¦å˜åŒ–å’Œèˆªå‘å˜åŒ–)
    avg_speed_variance = sum([
        sum([abs(p["speed"] - drone["performance_metrics"]["avg_speed"]) 
             for p in drone["trajectory"]]) / len(drone["trajectory"])
        for drone in flight_data["drones"]
    ]) / len(flight_data["drones"])
    trajectory_smoothness = max(0, 100 - avg_speed_variance * 5)
    flight_control_scores["trajectory_smoothness"] = min(100, trajectory_smoothness)
    
    # é«˜åº¦ç¨³å®šæ€§è¯„åˆ†
    altitude_variances = []
    for drone in flight_data["drones"]:
        altitudes = [p["altitude"] for p in drone["trajectory"]]
        avg_alt = sum(altitudes) / len(altitudes)
        variance = sum([(alt - avg_alt) ** 2 for alt in altitudes]) / len(altitudes)
        altitude_variances.append(variance)
    avg_altitude_variance = sum(altitude_variances) / len(altitude_variances)
    altitude_stability = max(0, 100 - avg_altitude_variance / 10)
    flight_control_scores["altitude_stability"] = min(100, altitude_stability)
    
    # é€Ÿåº¦ä¸€è‡´æ€§è¯„åˆ†
    speed_consistency = max(0, 100 - avg_speed_variance * 3)
    flight_control_scores["speed_consistency"] = min(100, speed_consistency)
    
    # èƒ½æºæ•ˆç‡è¯„åˆ† (åŸºäºç”µæ± æ¶ˆè€—)
    avg_battery_consumption = sum([
        drone["performance_metrics"]["battery_consumption"] 
        for drone in flight_data["drones"]
    ]) / len(flight_data["drones"])
    energy_efficiency = max(0, 200 - avg_battery_consumption * 2)
    flight_control_scores["energy_efficiency"] = min(100, energy_efficiency)
    
    scores["flight_control"] = flight_control_scores
    
    # 2. é›†ç¾¤ååŒè¯„åˆ†
    swarm_coordination_scores = {}
    
    # ç¼–é˜Ÿç¨³å®šæ€§è¯„åˆ†
    formation_stability = flight_data["swarm_metrics"]["formation_stability"]
    swarm_coordination_scores["formation_stability"] = formation_stability
    
    # é€šä¿¡è´¨é‡è¯„åˆ†
    communication_quality = flight_data["swarm_metrics"]["communication_success_rate"]
    swarm_coordination_scores["communication_quality"] = communication_quality
    
    # åè°ƒå»¶è¿Ÿè¯„åˆ† (å»¶è¿Ÿè¶Šä½åˆ†æ•°è¶Šé«˜)
    coordination_delay = flight_data["swarm_metrics"]["coordination_delay_avg"]
    coordination_delay_score = max(0, 100 - coordination_delay / 2)
    swarm_coordination_scores["coordination_delay"] = coordination_delay_score
    
    # ä»»åŠ¡å®Œæˆåº¦è¯„åˆ†
    task_completion = flight_data["swarm_metrics"]["task_completion_rate"]
    swarm_coordination_scores["task_completion"] = task_completion

    # å•æœºä»»åŠ¡ï¼šååŒè¯„åˆ†ä¸é€‚ç”¨ï¼Œç½®é›¶å¹¶æ ‡è®°
    if int(flight_data.get("drone_count", 1)) <= 1:
        swarm_coordination_scores["formation_stability"] = 0.0
        swarm_coordination_scores["communication_quality"] = 0.0
        swarm_coordination_scores["coordination_delay"] = 0.0
        swarm_coordination_scores["task_completion"] = 0.0
        swarm_coordination_scores["not_applicable"] = True
    
    scores["swarm_coordination"] = swarm_coordination_scores
    
    # 3. å®‰å…¨è¯„ä¼°è¯„åˆ†
    safety_assessment_scores = {}
    
    # é¿ç¢°èƒ½åŠ›è¯„åˆ† (åŸºäºé¿ç¢°äº‹ä»¶æ•°é‡)
    collision_events = flight_data["swarm_metrics"]["collision_avoidance_events"]
    collision_avoidance = max(0, 100 - collision_events * 15)
    safety_assessment_scores["collision_avoidance"] = collision_avoidance
    
    # åº”æ€¥å“åº”è¯„åˆ† (åŸºäºå¼‚å¸¸å¤„ç†)
    total_anomalies = sum([len(drone["anomalies"]) for drone in flight_data["drones"]])
    emergency_response = max(0, 100 - total_anomalies * 10)
    safety_assessment_scores["emergency_response"] = emergency_response
    
    # é£é™©ç®¡æ§è¯„åˆ† (ç»¼åˆè¯„ä¼°)
    risk_factors = collision_events + total_anomalies
    risk_management = max(0, 100 - risk_factors * 8)
    safety_assessment_scores["risk_management"] = risk_management
    
    scores["safety_assessment"] = safety_assessment_scores
    
    return scores


def calculate_weighted_scores(scores):
    """
    è®¡ç®—åŠ æƒç»¼åˆè¯„åˆ†
    """
    weighted_scores = {}
    total_score = 0.0
    
    for category, category_data in SCORING_CRITERIA.items():
        # è·³è¿‡å·²ç¦ç”¨çš„ç±»åˆ«ï¼ˆä¾‹å¦‚è½¨è¿¹è¯„ä¼°ï¼‰
        if category_data.get("disabled", False):
            continue
        category_score = 0.0
        category_weighted_score = 0.0
 
         # ååŒè¯„åˆ†åœ¨å•æœºä»»åŠ¡ä¸‹ä¸é€‚ç”¨
        not_applicable = bool(scores.get(category, {}).get("not_applicable", False))
         
        if not not_applicable:
            for metric, metric_data in category_data["metrics"].items():
                metric_score = scores[category][metric]
                weighted_metric_score = metric_score * metric_data["weight"]
                category_score += weighted_metric_score
             
            category_weighted_score = category_score * category_data["weight"]
            total_score += category_weighted_score
 
        weighted_scores[category] = {
            "score": category_score,
            "weighted_score": category_weighted_score,
            "details": scores[category],
            "not_applicable": not_applicable
        }
     
    weighted_scores["total_score"] = total_score
    return weighted_scores


def generate_expert_scoring(agent_name, flight_data, scores):
    """
    ä¸ºä¸“å®¶ç”Ÿæˆä¸“ä¸šè¯„åˆ†å’Œåˆ†æ
    """
    agent_info = AGENTS[agent_name]
    expert_scoring = {
        "expert": agent_name,
        "expertise": agent_info["expertise"],
        "focused_metrics": {},
        "professional_analysis": "",
        "recommendations": []
    }
    
    # æå–è¯¥ä¸“å®¶å…³æ³¨çš„è¯„åˆ†æŒ‡æ ‡
    for category in ["flight_control", "swarm_coordination", "safety_assessment"]:
        if category == "swarm_coordination" and int(flight_data.get("drone_count", 1)) <= 1:
            continue  # å•æœºä»»åŠ¡ï¼šååŒè¯„åˆ†ä¸é€‚ç”¨
        if category in scores:
            for metric in agent_info["scoring_focus"]:
                if metric in scores[category]:
                    expert_scoring["focused_metrics"][metric] = scores[category][metric]
    
    # è®¡ç®—ä¸“å®¶ä¸“ä¸šè¯„åˆ† (åŸºäºå…³æ³¨æŒ‡æ ‡çš„åŠ æƒå¹³å‡)
    if expert_scoring["focused_metrics"]:
        expert_score = sum(expert_scoring["focused_metrics"].values()) / len(expert_scoring["focused_metrics"])
        expert_scoring["expert_score"] = round(expert_score, 2)
    else:
        expert_scoring["expert_score"] = None
        expert_scoring["note"] = "å•æœºä»»åŠ¡ï¼ŒååŒè¯„åˆ†ä¸é€‚ç”¨"
    
    return expert_scoring


def generate_scoring_report(flight_data, scores, weighted_scores, expert_scorings):
    """
    ç”Ÿæˆç»¼åˆè¯„åˆ†æŠ¥å‘Š
    """
    report = {
        "evaluation_summary": {
            "total_score": round(weighted_scores["total_score"], 2),
            "grade": get_performance_grade(weighted_scores["total_score"]),
            "evaluation_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "drone_count": len(flight_data["drones"]),
            "mission_duration": flight_data["mission_info"]["duration_minutes"]
        },
        "category_scores": {},
        "expert_evaluations": expert_scorings,
        "detailed_metrics": scores,
        "recommendations": generate_recommendations(weighted_scores, expert_scorings),
        "performance_analysis": generate_performance_analysis(weighted_scores)
    }
    
    # åˆ†ç±»è¯„åˆ†è¯¦æƒ…
    for category, data in weighted_scores.items():
        if category != "total_score":
            grade = get_performance_grade(data["score"])
            note = ""
            if data.get("not_applicable"):
                grade = "N/A"
                note = "å•æœºä»»åŠ¡ï¼ŒååŒè¯„åˆ†ä¸é€‚ç”¨"
            report["category_scores"][category] = {
                "name": SCORING_CRITERIA[category]["name"],
                "score": round(data["score"], 2),
                "weighted_score": round(data["weighted_score"], 2),
                "weight": SCORING_CRITERIA[category]["weight"],
                "grade": grade,
                "note": note
            }
    
    return report


def get_performance_grade(score):
    """
    æ ¹æ®åˆ†æ•°è·å–ç­‰çº§
    """
    if score >= 90:
        return "ä¼˜ç§€"
    elif score >= 80:
        return "è‰¯å¥½"
    elif score >= 70:
        return "ä¸­ç­‰"
    elif score >= 60:
        return "åŠæ ¼"
    else:
        return "ä¸åŠæ ¼"


def generate_recommendations(weighted_scores, expert_scorings):
    """
    ç”Ÿæˆæ”¹è¿›å»ºè®®
    """
    recommendations = []
    
    # åŸºäºåˆ†æ•°ç”Ÿæˆå»ºè®®
    for category, data in weighted_scores.items():
        if category != "total_score" and data["score"] < 80:
            if data.get("not_applicable"):
                continue
            category_name = SCORING_CRITERIA[category]["name"]
            if data["score"] < 60:
                recommendations.append(f"{category_name}è¡¨ç°ä¸ä½³ï¼Œéœ€è¦é‡ç‚¹æ”¹è¿›")
            elif data["score"] < 80:
                recommendations.append(f"{category_name}æœ‰æå‡ç©ºé—´ï¼Œå»ºè®®ä¼˜åŒ–")
    
    # åŸºäºä¸“å®¶è¯„åˆ†ç”Ÿæˆå»ºè®®
    for expert_scoring in expert_scorings:
        if expert_scoring.get("expert_score") is not None and expert_scoring["expert_score"] < 75:
            recommendations.append(f"å»ºè®®é‡ç‚¹å…³æ³¨{expert_scoring['expert']}æå‡ºçš„ä¸“ä¸šå»ºè®®")
    
    return recommendations


def generate_performance_analysis(weighted_scores):
    """
    ç”Ÿæˆæ€§èƒ½åˆ†æ
    """
    analysis = {
        "strengths": [],
        "weaknesses": [],
        "overall_assessment": ""
    }
    
    # åˆ†æä¼˜åŠ¿å’ŒåŠ£åŠ¿
    for category, data in weighted_scores.items():
        if category != "total_score":
            category_name = SCORING_CRITERIA[category]["name"]
            if data["score"] >= 85:
                analysis["strengths"].append(f"{category_name}è¡¨ç°ä¼˜ç§€")
            elif data["score"] < 70:
                analysis["weaknesses"].append(f"{category_name}éœ€è¦æ”¹è¿›")
    
    # æ€»ä½“è¯„ä¼°
    total_score = weighted_scores["total_score"]
    if total_score >= 85:
        analysis["overall_assessment"] = "æ— äººæœºé›†ç¾¤æ•´ä½“è¡¨ç°ä¼˜ç§€ï¼Œå„é¡¹æŒ‡æ ‡å‡è¾¾åˆ°è¾ƒé«˜æ°´å¹³"
    elif total_score >= 75:
        analysis["overall_assessment"] = "æ— äººæœºé›†ç¾¤è¡¨ç°è‰¯å¥½ï¼Œéƒ¨åˆ†æŒ‡æ ‡ä»æœ‰ä¼˜åŒ–ç©ºé—´"
    elif total_score >= 65:
        analysis["overall_assessment"] = "æ— äººæœºé›†ç¾¤è¡¨ç°ä¸­ç­‰ï¼Œéœ€è¦åœ¨å¤šä¸ªæ–¹é¢è¿›è¡Œæ”¹è¿›"
    else:
        analysis["overall_assessment"] = "æ— äººæœºé›†ç¾¤è¡¨ç°ä¸ä½³ï¼Œéœ€è¦å…¨é¢ä¼˜åŒ–å’Œæ”¹è¿›"
    
    return analysis


def call_glm_api(prompt, api_key, agent_role=""):
    base_url = os.environ.get("ZHIPU_BASE_URL", "").strip()
    client_kwargs = {"api_key": api_key}
    if base_url:
        client_kwargs["base_url"] = base_url
    client = ZhipuAiClient(**client_kwargs)
    messages = [
        {"role": "system", "content": f"ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚{agent_role}".strip()},
        {"role": "user", "content": prompt}
    ]
    response = client.chat.completions.create(
        model="glm-4.6",
        messages=messages,
        temperature=0.6
    )
    return response.choices[0].message.content


def construct_message(agents_responses, question, agent_id):
    """
    ç”Ÿæˆç»“æ„åŒ–è·Ÿè¿›æç¤ºï¼Œè¦æ±‚è¾“å‡ºå›ºå®šå—ä»¥æå‡ä¿¡æ¯å¯†åº¦ï¼š
    [CLAIM][EVIDENCE][COUNTER][SUMMARY][CONFIDENCE]
    å¹¶æŒ‡å®šä¸€ä¸ªè´¨è¯¢ç›®æ ‡ä»¥ä¿ƒä½¿ç›´æ¥åé©³ã€‚
    """
    if not agents_responses:
        return (
            f"é—®é¢˜: {question}\n\n"
            "è¯·ä½¿ç”¨ä»¥ä¸‹ä¸¥æ ¼ç»“æ„åŒ–æ ¼å¼(ASCII):\n"
            "[CLAIM] ä¸€å¥æ ¸å¿ƒåˆ¤æ–­\n"
            "[EVIDENCE] 3-5æ¡è¯æ®(å«å…·ä½“æ•°å€¼)\n"
            "[COUNTER] é’ˆå¯¹æ½œåœ¨åé©³çš„æœ€å°å˜æ›´å›åº”\n"
            "[SUMMARY] 3ç‚¹ç»¼åˆ + 1æ¡è¡ŒåŠ¨å»ºè®®\n"
            "[CONFIDENCE] 0.00~1.00\n"
        )

    target_id = (agent_id + 1) % max(1, len(agents_responses))
    prefix = [
        f"é—®é¢˜: {question}",
        "ä¸Šä¸€è½®å…¶ä»–ä¸“å®¶çš„å›ç­”è¦ç‚¹(æˆªæ–­):",
    ]
    for i, response in enumerate(agents_responses):
        if i != agent_id:
            preview = str(response).strip().replace("\n", " ")
            prefix.append(f"- ä¸“å®¶{i+1}: {preview[:400]}")
    prefix.append(
        "\nè¯·ä¸¥æ ¼ä½¿ç”¨ä»¥ä¸‹ç»“æ„åŒ–æ ¼å¼(ASCII):\n"
        "[CLAIM] ä¸€å¥æ ¸å¿ƒåˆ¤æ–­\n"
        "[EVIDENCE] 3-5æ¡è¯æ®(å«å…·ä½“æ•°å€¼)\n"
        f"[COUNTER] é’ˆå¯¹ä¸“å®¶{target_id+1}å…³é”®è®ºç‚¹çš„åé©³æˆ–è¾¹ç•Œæ¡ä»¶\n"
        "[SUMMARY] 3ç‚¹ç»¼åˆ + 1æ¡è¡ŒåŠ¨å»ºè®®\n"
        "[CONFIDENCE] 0.00~1.00\n"
    )
    return "\n".join(prefix)


def load_trajectory_from_pkl(file_path):
    """
    ä» trajectory.pkl åŠ è½½è½¨è¿¹å¹¶è½¬æ¢ä¸º flight_data ç»“æ„
    æ”¯æŒ numpy.ndarrayã€dictã€list ç­‰å¸¸è§æ ¼å¼
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°è½¨è¿¹æ–‡ä»¶: {file_path}")
    with open(file_path, 'rb') as f:
        data = pickle.load(f)

    # æå–æ•°ç»„ï¼ˆæ”¯æŒåµŒå¥—ç»“æ„ï¼‰
    preferred_keys = {"trajectory", "positions", "observations", "coords", "path"}
    found = []

    def is_numeric(x):
        return isinstance(x, (int, float, np.integer, np.floating))

    def is_numeric_list(lst):
        return isinstance(lst, list) and len(lst) > 0 and all(is_numeric(e) for e in lst)

    def is_numeric_2d_list(lst):
        return isinstance(lst, (list, tuple)) and len(lst) > 0 and all(
            isinstance(e, (list, tuple)) and len(e) > 0 and all(is_numeric(v) for v in e)
            for e in lst
        )

    def collect(obj, path=""):
        if isinstance(obj, np.ndarray):
            found.append((obj, path))
        elif isinstance(obj, dict):
            for k, v in obj.items():
                new_path = f"{path}.{k}" if path else str(k)
                collect(v, new_path)
        elif isinstance(obj, (list, tuple)):
            if is_numeric_2d_list(obj) or is_numeric_list(obj):
                found.append((np.array(obj, dtype=np.float64), path))
            else:
                for i, v in enumerate(obj):
                    new_path = f"{path}[{i}]" if path else f"[{i}]"
                    collect(v, new_path)

    collect(data)

    arr = None
    if found:
        # ä¼˜å…ˆé€‰æ‹©è·¯å¾„ä¸­åŒ…å«å¸¸è§é”®åçš„æ•°ç»„ï¼Œå…¶æ¬¡é€‰æ‹©æœ€å¤§æ•°ç»„
        prioritized = [a for a in found if any(k in a[1] for k in preferred_keys)]
        if prioritized:
            arr = max(prioritized, key=lambda x: x[0].size)[0]
        else:
            arr = max(found, key=lambda x: x[0].size)[0]

    # è½¨è¿¹å½¢çŠ¶å¤„ç†ï¼šè‡³å°‘éœ€è¦ Xã€Yï¼ŒZ å¯é€‰
    if arr.ndim == 1:
        arr = arr.reshape(-1, 2)
    elif arr.shape[1] < 2:
        # å¦‚æœåˆ—ä¸è¶³ï¼Œé‡å¤æˆ–å¡«å……åˆ°2åˆ—
        arr = np.pad(arr, ((0,0),(0, max(0,2-arr.shape[1]))), mode='edge')

    # ç”Ÿæˆå•æ— äººæœºçš„è½¨è¿¹ç‚¹
    traj = []
    total_distance = 0.0
    prev_xy = None
    max_speed = 0.0

    # æ—¶é—´æ­¥å‡è®¾ä¸º1ç§’
    for i in range(arr.shape[0]):
        x = float(arr[i, 0])
        y = float(arr[i, 1])
        alt = float(arr[i, 2]) if arr.shape[1] >= 3 else 120.0 + 5.0 * np.sin(i / 20.0)

        if prev_xy is None:
            speed = 0.0
            heading_deg = 0.0
        else:
            dx = x - prev_xy[0]
            dy = y - prev_xy[1]
            step_dist = float(np.hypot(dx, dy))
            total_distance += step_dist
            speed = step_dist  # å•ä½æ—¶é—´æ­¥è·ç¦»ï¼Œè§†ä¸ºé€Ÿåº¦
            heading_rad = np.arctan2(dy, dx)
            heading_deg = (np.degrees(heading_rad) + 360.0) % 360.0
            max_speed = max(max_speed, speed)
        prev_xy = (x, y)

        traj.append({
            "gps": {"lat": x, "lon": y},
            "altitude": alt,
            "speed": speed,
            "heading": heading_deg,
            "timestamp": i
        })

    avg_speed = float(np.mean([p["speed"] for p in traj]))
    battery_consumption = round(total_distance * 0.02 + len(traj) * 0.005, 2)  # ç®€å•ä¼°ç®—

    flight_data = {
        "mission_id": f"TRJ-{time.strftime('%Y%m%d%H%M%S')}",
        "mission_type": "è½¨è¿¹åˆ†æ",
        "drone_count": 1,
        "flight_duration": f"{len(traj)} æ­¥",
        "mission_info": {"duration_minutes": max(1, len(traj)//2)},
        "drones": [
            {
                "id": "DRONE-001",
                "trajectory": traj,
                "performance_metrics": {
                    "avg_speed": round(avg_speed, 3),
                    "max_speed": round(max_speed, 3),
                    "battery_consumption": battery_consumption,
                    "distance_traveled": round(total_distance, 3)
                },
                "anomalies": []
            }
        ],
        "swarm_metrics": {
            "formation_stability": 100.0,  # å•æœºè¿‘ä¼¼æ»¡åˆ†
            "communication_success_rate": 100.0,
            "coordination_delay_avg": 10.0,
            "task_completion_rate": 100.0,
            "collision_avoidance_events": 0
        }
    }

    return flight_data

# æå–è½¨è¿¹ç‚¹çš„é€šç”¨å­—æ®µ
def _extract_xy_alt_speed(traj_point):
    # æ”¯æŒä¸¤ç§ç»“æ„ï¼š{gps:{lat,lon}} æˆ– {latitude, longitude}
    if "gps" in traj_point:
        x = float(traj_point["gps"].get("lat", 0.0))
        y = float(traj_point["gps"].get("lon", 0.0))
    else:
        x = float(traj_point.get("latitude", traj_point.get("lat", 0.0)))
        y = float(traj_point.get("longitude", traj_point.get("lon", 0.0)))
    alt = float(traj_point.get("altitude", 0.0))
    speed = float(traj_point.get("speed", 0.0))
    heading = float(traj_point.get("heading", 0.0))
    t = int(traj_point.get("timestamp", 0))
    return x, y, alt, speed, heading, t

# èˆªå‘è½¬æŒ‡å—é’ˆæ–¹å‘
def _compass_from_heading(h):
    h = (h % 360.0)
    best = "N"; best_diff = 1e9
    for name, deg in COMPASS_DIRS:
        diff = min(abs(h - deg), 360 - abs(h - deg))
        if diff < best_diff:
            best_diff = diff
            best = name
    return best

# ç®€æ˜“ Ramerâ€“Douglasâ€“Peucker ç®—æ³•
def _rdp(points, epsilon=0.001):
    # ç®€æ˜“ Ramerâ€“Douglasâ€“Peuckerï¼Œå¤šæ•°åœºæ™¯å¤Ÿç”¨
    if len(points) < 3:
        return points
    def _perp_dist(pt, a, b):
        ax, ay = a; bx, by = b; px, py = pt
        dx, dy = bx - ax, by - ay
        if dx == 0 and dy == 0:
            return math.hypot(px - ax, py - ay)
        t = ((px - ax) * dx + (py - ay) * dy) / (dx * dx + dy * dy)
        t = max(0, min(1, t))
        cx, cy = ax + t * dx, ay + t * dy
        return math.hypot(px - cx, py - cy)
    def _rdp_rec(pts):
        if len(pts) <= 2:
            return pts
        a, b = pts[0], pts[-1]
        idx, dmax = 0, -1
        for i in range(1, len(pts) - 1):
            d = _perp_dist(pts[i], a, b)
            if d > dmax:
                idx, dmax = i, d
        if dmax > epsilon:
            left = _rdp_rec(pts[:idx+1])
            right = _rdp_rec(pts[idx:])
            return left[:-1] + right
        else:
            return [a, b]
    return _rdp_rec(points)

# ä¸º LLM ç”Ÿæˆè½¨è¿¹æ‘˜è¦
def summarize_trajectory_for_llm(flight_data, segments=6, max_events=10, rdp_epsilon=0.001, max_waypoints=8):
    traj = flight_data.get("drones", [{}])[0].get("trajectory", [])
    if not traj:
        return {"meta": {}, "stats": {}, "segments": [], "events": [], "waypoints": []}
    xs, ys, alts, speeds, headings, times = [], [], [], [], [], []
    for p in traj:
        x, y, alt, spd, hdg, t = _extract_xy_alt_speed(p)
        xs.append(x); ys.append(y); alts.append(alt); speeds.append(spd); headings.append(hdg); times.append(t)
    n = len(traj)
    duration_s = (times[-1] - times[0]) if times else n
    # è·ç¦»ï¼ˆè¿‘ä¼¼æ¬§æ°ï¼‰
    dist = 0.0
    turns = 0
    accel_events = 0
    decel_events = 0
    sharp_turns = []
    climb_events = []
    for i in range(1, n):
        dist += math.hypot(xs[i] - xs[i-1], ys[i] - ys[i-1])
        dh = abs(headings[i] - headings[i-1])
        dh = min(dh, 360 - dh)
        if dh >= 30:
            turns += 1
            sharp_turns.append({"t": times[i], "angle_deg": round(dh, 1)})
        dv = speeds[i] - speeds[i-1]
        if dv >= 2.0:
            accel_events += 1
        elif dv <= -2.0:
            decel_events += 1
        # çˆ¬å‡äº‹ä»¶ï¼šè¿ç»­ä¸Šå‡é€Ÿç‡é˜ˆå€¼
        rate = (alts[i] - alts[i-1]) / max(1, (times[i] - times[i-1]))
        if rate >= 3.0:
            climb_events.append({"t": times[i], "rate_mps": round(rate, 2)})
    speed_mean = float(np.mean(speeds)) if speeds else 0.0
    speed_std = float(np.std(speeds)) if speeds else 0.0
    speed_max = float(np.max(speeds)) if speeds else 0.0
    alt_mean = float(np.mean(alts)) if alts else 0.0
    alt_std = float(np.std(alts)) if alts else 0.0
    heading_std = float(np.std(headings)) if headings else 0.0
    smoothness_index = 1.0 / (1.0 + heading_std / 90.0)
    # åˆ†æ®µ
    seg_len = max(1, n // segments)
    segs = []
    for s in range(segments):
        i0 = s * seg_len
        i1 = min(n, (s+1) * seg_len)
        if i0 >= n:
            break
        v_mean = float(np.mean(speeds[i0:i1])) if i1 > i0 else 0.0
        v_std = float(np.std(speeds[i0:i1])) if i1 > i0 else 0.0
        a_mean = float(np.mean(alts[i0:i1])) if i1 > i0 else 0.0
        a_std = float(np.std(alts[i0:i1])) if i1 > i0 else 0.0
        h_mean = float(np.mean(headings[i0:i1])) if i1 > i0 else 0.0
        dir_str = _compass_from_heading(h_mean)
        turns_seg = 0
        for j in range(i0+1, i1):
            dh = abs(headings[j] - headings[j-1]); dh = min(dh, 360 - dh)
            if dh >= 30: turns_seg += 1
        turn_intensity = "low" if turns_seg <= 1 else ("medium" if turns_seg <= 3 else "high")
        segs.append({
            "t0": int(times[i0]), "t1": int(times[i1-1]) if i1 > i0 else int(times[i0]),
            "dir": dir_str,
            "v_mean": round(v_mean, 2), "v_std": round(v_std, 2),
            "alt_mean": round(a_mean, 1), "alt_std": round(a_std, 1),
            "turn_intensity": turn_intensity
        })
    # äº‹ä»¶æ—¶é—´è½´ï¼ˆè£å‰ªï¼‰
    events = []
    for e in sharp_turns[:max_events]:
        events.append({"t": e["t"], "type": "sharp_turn", "angle_deg": e["angle_deg"]})
    for e in climb_events[:max_events - len(events)]:
        events.append({"t": e["t"], "type": "climb", "rate_mps": e["rate_mps"]})
    # Waypoints via RDP
    pts = list(zip(xs, ys))
    wps = _rdp(pts, epsilon=rdp_epsilon)
    if len(wps) > max_waypoints:
        step = max(1, len(wps) // max_waypoints)
        wps = wps[::step][:max_waypoints]
    summary = {
        "meta": {"duration_s": int(duration_s), "n_points": n},
        "stats": {
            "distance_km": round(dist / 1000.0, 3),
            "speed_mean_mps": round(speed_mean, 3), "speed_std_mps": round(speed_std, 3), "speed_max_mps": round(speed_max, 3),
            "alt_mean_m": round(alt_mean, 1), "alt_std_m": round(alt_std, 1),
            "turn_count_gt30deg": int(turns),
            "smoothness_index": round(smoothness_index, 3)
        },
        "segments": segs,
        "events": events,
        "waypoints": [[round(a,6), round(b,6)] for a,b in wps]
    }
    return summary

# å°†æ‘˜è¦æ ¼å¼åŒ–ä¸ºç´§å‡‘ DSL
def format_llm_dsl(summary, scores=None):
    meta = summary.get("meta", {})
    stats = summary.get("stats", {})
    segs = summary.get("segments", [])
    events = summary.get("events", [])
    wps = summary.get("waypoints", [])
    lines = []
    lines.append(f"META: dur={meta.get('duration_s',0)}s, pts={meta.get('n_points',0)}")
    lines.append(
        "STATS: "
        f"L={stats.get('distance_km',0)}km, "
        f"v={stats.get('speed_mean_mps',0)}Â±{stats.get('speed_std_mps',0)}m/s, "
        f"vmax={stats.get('speed_max_mps',0)}m/s, "
        f"alt={stats.get('alt_mean_m',0)}Â±{stats.get('alt_std_m',0)}m, "
        f"turns>30Â°={stats.get('turn_count_gt30deg',0)}, "
        f"smooth={stats.get('smoothness_index',0)}"
    )
    for i, s in enumerate(segs[:8], 1):
        lines.append(
            f"SEG[{i}]: t={s.get('t0',0)}-{s.get('t1',0)}, dir={s.get('dir','')}, "
            f"v={s.get('v_mean',0)}Â±{s.get('v_std',0)}, alt={s.get('alt_mean',0)}Â±{s.get('alt_std',0)}, "
            f"turn={s.get('turn_intensity','low')}"
        )
    for e in events[:10]:
        if e.get('type') == 'sharp_turn':
            lines.append(f"EVENT: t={e['t']}, sharp_turn={e['angle_deg']}deg")
        elif e.get('type') == 'climb':
            lines.append(f"EVENT: t={e['t']}, climb={e['rate_mps']}m/s")
    if wps:
        wp_str = "â†’".join([f"({a},{b})" for a,b in wps])
        lines.append(f"WAYPTS: {wp_str}")
    if scores:
        try:
            sc = scores.get('swarm_coordination', {})
            if sc.get('not_applicable'):
                lines.append("SCORES: COORD=N/A (å•æœºä»»åŠ¡)")
            else:
                lines.append(
                    "SCORES: "
                    f"formation_stab={sc.get('formation_stability',0)}, "
                    f"comm_quality={sc.get('communication_quality',0)}, "
                    f"coord_delay={sc.get('coordination_delay',0)}, "
                    f"task_comp={sc.get('task_completion',0)}"
                )
        except Exception:
            pass
    return "\n".join(lines)


def main():
    from debate_protocol import structured_prompt_first_round, construct_structured_followup, parse_structured_response, update_agent_weights, summary_similarity
    api_key = 'd2811fc4f03f48f2bb547d6a6b3378f4.GtaNMZOyqulNGa1L'
    print("ğŸš æ­£åœ¨åŠ è½½è½¨è¿¹æ–‡ä»¶: c:\\Users\\bafs\\Desktop\\llm_multiagent_debate-main\\trajectory.pkl")
    flight_data = load_trajectory_from_pkl(r"c:\\Users\\bafs\\Desktop\\llm_multiagent_debate-main\\trajectory.pkl")
    print("âœ… å·²ä» trajectory.pkl åŠ è½½è½¨è¿¹æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºè¯„ä¼°ç»“æ„")


    # ä¿å­˜é£è¡Œæ•°æ®
    with open("drone_flight_data.json", "w", encoding="utf-8") as f:
        json.dump(flight_data, f, ensure_ascii=False, indent=2)
    print("âœ… é£è¡Œæ•°æ®å·²ä¿å­˜åˆ° drone_flight_data.json")
    
    # è®¾ç½®è¾©è®ºå‚æ•°
    agents = 0  # å ä½ï¼Œç¨åæ ¹æ®AGENTSé‡è®¾
    rounds = 2  # 2è½®è¾©è®º
    
    # æ™ºèƒ½ä½“è§’è‰²è®¾å®š - ç§»åŠ¨åˆ°mainå‡½æ•°å¼€å§‹å¤„
    global AGENTS
    AGENTS = {

        "ç¾¤èšèƒ½åŠ›ä¸“å®¶": {
            "role": "ç¾¤èšèƒ½åŠ›ä¸“å®¶",
            "expertise": "ç¾¤ä½“è¡Œä¸ºå»ºæ¨¡ã€é˜Ÿå½¢ä¿æŒã€å¯†åº¦æ§åˆ¶ä¸é‚»åŸŸäº¤äº’",
            "scoring_focus": ["formation_stability", "communication_quality", "coordination_delay", "task_completion"],
            "evaluation_prompt": "ä½œä¸ºç¾¤èšèƒ½åŠ›ä¸“å®¶ï¼Œè¯·è¯„ä¼°ç¾¤ä½“èšåˆã€é˜Ÿå½¢ä¿æŒä¸ååŒè¡Œä¸ºè´¨é‡ï¼Œç»“åˆç¼–é˜Ÿç¨³å®šæ€§ã€é€šä¿¡è´¨é‡ã€åè°ƒå»¶è¿Ÿä¸ä»»åŠ¡å®Œæˆåº¦å››é¡¹æŒ‡æ ‡ï¼Œå¼•ç”¨å…·ä½“è¯æ®å¹¶ç»™å‡ºä½æˆæœ¬çš„ç¾¤èšç­–ç•¥æ”¹è¿›å»ºè®®ï¼›å•æœºä»»åŠ¡ä¸‹ååŒç›¸å…³é¡¹è§†ä¸ºN/Aã€‚"
        },
         "é›†ç¾¤ååŒä¸é€šä¿¡å·¥ç¨‹å¸ˆ": {
             "role": "é›†ç¾¤ååŒä¸é€šä¿¡å·¥ç¨‹å¸ˆ",
             "expertise": "é˜Ÿå½¢æ§åˆ¶ã€ä»»åŠ¡åˆ†é…ã€ç½‘ç»œé€šä¿¡ä¸é“¾è·¯è´¨é‡",
             "scoring_focus": ["formation_stability", "communication_quality", "coordination_delay", "task_completion"],
             "evaluation_prompt": "ä½œä¸ºé›†ç¾¤ååŒä¸é€šä¿¡å·¥ç¨‹å¸ˆï¼Œè¯·é‡ç‚¹è¯„ä¼°ç¼–é˜Ÿç¨³å®šæ€§ã€é€šä¿¡è´¨é‡ã€åè°ƒå»¶è¿Ÿå’Œä»»åŠ¡å®Œæˆåº¦ï¼›è‹¥ä¸ºå•æœºä»»åŠ¡è¯·æ˜ç¡®ååŒé¡¹ä¸ºN/Aï¼›å¼•ç”¨å…·ä½“æŒ‡æ ‡å¹¶æå‡ºè½»é‡çº§ååŒç­–ç•¥è°ƒæ•´ã€‚"
         },
         "ä»»åŠ¡å®Œæˆåº¦è¯„ä¼°ä¸“å®¶": {
             "role": "ä»»åŠ¡å®Œæˆåº¦è¯„ä¼°ä¸“å®¶",
             "expertise": "ä»»åŠ¡è§„åˆ’ä¸æ‰§è¡Œã€é‡Œç¨‹ç¢‘ç®¡ç†ã€èµ„æºä¸è½½è·è°ƒåº¦",
             "scoring_focus": ["task_completion", "coordination_delay", "communication_quality"],
             "evaluation_prompt": "ä½œä¸ºä»»åŠ¡å®Œæˆåº¦è¯„ä¼°ä¸“å®¶ï¼Œè¯·ç»“åˆä»»åŠ¡å®Œæˆç‡ã€åè°ƒå»¶è¿Ÿä¸é€šä¿¡è´¨é‡ï¼Œè¯†åˆ«å½±å“ä»»åŠ¡è¾¾æˆçš„ç“¶é¢ˆï¼Œå¹¶æå‡ºå¯æ‰§è¡Œçš„ä¼˜åŒ–å»ºè®®ï¼›å•æœºä»»åŠ¡ä¸‹ååŒç›¸å…³é¡¹è§†ä¸ºN/Aã€‚"
         }
     }
    # æ ¹æ®æ–°çš„ä¸“å®¶é›†åˆé‡è®¾æ•°é‡
    agents = len(AGENTS)
     
     # ä¿æŒå‘åå…¼å®¹çš„è§’è‰²æè¿°
    agent_roles = [
        "ä½œä¸ºç¾¤èšèƒ½åŠ›ä¸“å®¶ï¼Œä»ç¾¤ä½“èšåˆä¸ååŒè§’åº¦",
        "ä½œä¸ºé›†ç¾¤ååŒä¸é€šä¿¡å·¥ç¨‹å¸ˆï¼Œä»åä½œä¸ç½‘ç»œè§’åº¦", 
        "ä½œä¸ºä»»åŠ¡å®Œæˆåº¦è¯„ä¼°ä¸“å®¶ï¼Œä»ä»»åŠ¡æ‰§è¡Œä¸è¾¾æˆè§’åº¦"
    ]
    
    # åˆå§‹åŒ–æ™ºèƒ½ä½“å›ç­”
    agents_responses = [[] for _ in range(agents)]
    agents_structured = [[] for _ in range(agents)]
    agent_weights = [1.0 / agents] * agents
    weights_history = []
    
    print(f"\nğŸ¤– æ™ºè°±GLM-4.6 æ— äººæœºé›†ç¾¤è¯„ä¼°ç³»ç»Ÿ")
    print(f"è¾©è®ºé—®é¢˜: {DEBATE_QUESTION}\n")
        
        # æ˜¾ç¤ºé£è¡Œæ•°æ®æ‘˜è¦
    print("ğŸ“Š é£è¡Œæ•°æ®æ‘˜è¦:")
    print(f"  - ä»»åŠ¡ID: {flight_data['mission_id']}")
    print(f"  - ä»»åŠ¡ç±»å‹: {flight_data['mission_type']}")
    print(f"  - æ— äººæœºæ•°é‡: {flight_data['drone_count']} æ¶")
    print(f"  - é£è¡Œæ—¶é•¿: {flight_data['flight_duration']}")
    print(f"  - é›†ç¾¤ç¨³å®šæ€§: {'N/A(å•æœº)' if flight_data['drone_count'] <= 1 else str(flight_data['swarm_metrics']['formation_stability']) + '%'}")
    print(f"  - ä»»åŠ¡å®Œæˆç‡: {'N/A(å•æœº)' if flight_data['drone_count'] <= 1 else str(flight_data['swarm_metrics']['task_completion_rate']) + '%'}")
    
    print("\nå‚ä¸è¯„ä¼°çš„ä¸“å®¶:")
    for i, role in enumerate(agent_roles):
        print(f"  ä¸“å®¶ {i+1}: {role}")
    print("\n" + "="*60)
    
    # ç”Ÿæˆé£è¡Œæ•°æ®æ‘˜è¦
    swarm_stab_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['formation_stability']}%"
    comm_rate_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['communication_success_rate']}%"
    task_comp_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['task_completion_rate']}%"
    avoid_events_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['collision_avoidance_events']} æ¬¡"
    coord_delay_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['coordination_delay_avg']} ms"
    flight_summary = f"""
    åŸºäºä»¥ä¸‹æ— äººæœºé›†ç¾¤é£è¡Œæ•°æ®è¿›è¡Œåˆ†æï¼š
    - ä»»åŠ¡ç±»å‹ï¼š{flight_data['mission_type']}
    - æ— äººæœºæ•°é‡ï¼š{flight_data['drone_count']} æ¶
    - é£è¡Œæ—¶é•¿ï¼š{flight_data['flight_duration']}
    - é›†ç¾¤ç¨³å®šæ€§ï¼š{swarm_stab_str}
    - é€šä¿¡æˆåŠŸç‡ï¼š{comm_rate_str}
    - ä»»åŠ¡å®Œæˆç‡ï¼š{task_comp_str}
    - é¿ç¢°äº‹ä»¶ï¼š{avoid_events_str}
    - å¹³å‡åè°ƒå»¶è¿Ÿï¼š{coord_delay_str}"""
        
        # æ›´æ–°æ™ºèƒ½ä½“å¾ªç¯ä»¥ä½¿ç”¨æ–°çš„AGENTSå­—å…¸
    agent_names = list(AGENTS.keys())
        
        # ç”Ÿæˆè‡ªåŠ¨è¯„åˆ†
    print("æ­£åœ¨è®¡ç®—é£è¡Œæ•°æ®è¯„åˆ†...")
    scores = calculate_flight_scores(flight_data)
    weighted_scores = calculate_weighted_scores(scores)
    
    # ä¸ºLLMç”Ÿæˆç´§å‡‘è½¨è¿¹è¯æ®DSL
    traj_summary = summarize_trajectory_for_llm(flight_data)
    evidence_text = format_llm_dsl(traj_summary, scores=scores)
    try:
        attn = compute_traj_attention(flight_data.get("drones", [{}])[0].get("trajectory", []))
        evidence_text = evidence_text + "\n" + build_attn_dsl_block(flight_data.get("drones", [{}])[0].get("trajectory", []), attn)
        print("ğŸ§ª å·²ç”Ÿæˆè½¨è¿¹æ‘˜è¦DSL(å·²æ³¨å…¥åˆ°æç¤º): META/SEG/EVENT/WAYPTS/SCORES/ATTN")
    except Exception:
        print("âš ï¸ æ³¨æ„åŠ›æ‘˜è¦æ„å»ºå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹DSL")
    # æ‰“å°æŠ½è±¡ç»“æœï¼šJSONä¸DSL
    print("\n====== è½¨è¿¹æ‘˜è¦(JSON) ======")
    print(json.dumps(traj_summary, ensure_ascii=False, indent=2))
    print("\n====== è½¨è¿¹æ‘˜è¦(DSL) ======")
    print(evidence_text)
    print("="*60)
    
    # ç”Ÿæˆä¸“å®¶è¯„åˆ†
    expert_scorings = []
    for agent_name in agent_names:
        expert_scoring = generate_expert_scoring(agent_name, flight_data, scores)
        expert_scorings.append(expert_scoring)
    
    print(f"è‡ªåŠ¨è¯„åˆ†å®Œæˆï¼Œæ€»åˆ†: {weighted_scores['total_score']:.2f}")
    
    # è¿›è¡Œè¾©è®º
    for round_idx in range(rounds):
        print(f"\nğŸ”¥ ç¬¬ {round_idx+1} è½®è¯„ä¼°")
        print("-" * 40)
        
        for agent_idx in range(agents):
            agent_name = agent_names[agent_idx]
            agent_info = AGENTS[agent_name]
            
            print(f"\nğŸ’­ {agent_name} æ­£åœ¨åˆ†æ...")
            
            # æ„å»ºæç¤ºï¼ŒåŒ…å«é£è¡Œæ•°æ®å’Œè¯„åˆ†
            if round_idx == 0:
                # ç¬¬ä¸€è½®ï¼šåŸºäºé£è¡Œæ•°æ®å’Œè‡ªåŠ¨è¯„åˆ†è¿›è¡Œåˆ†æ
                prompt = structured_prompt_first_round(
                    agent_info,
                    flight_summary,
                    weighted_scores,
                    expert_scorings[agent_idx],
                    DEBATE_QUESTION,
                    evidence_text=evidence_text,
                )
            else:
                # åç»­è½®æ¬¡ï¼Œè€ƒè™‘å…¶ä»–ä¸“å®¶çš„åˆ†æ
                last_round_responses = [agents_responses[i][round_idx-1] for i in range(agents)]
                prompt = construct_structured_followup(
                    last_round_responses,
                    DEBATE_QUESTION,
                    agent_idx,
                    weighted_scores,
                    expert_scorings[agent_idx],
                    evidence_text=evidence_text,
                )
            
            # è°ƒç”¨APIè·å–å›ç­”
            print("æ­£åœ¨è°ƒç”¨æ™ºè°±GLM-4.6 API...")
            response = call_glm_api(prompt, api_key, agent_info['role'])

            agents_responses[agent_idx].append(response)
            # è§£æç»“æ„åŒ–è¾“å‡ºå¹¶ä¿å­˜
            try:
                structured = parse_structured_response(response)
            except Exception:
                structured = {"summary": "", "confidence": 0.5, "raw": response}
            agents_structured[agent_idx].append(structured)
            
            print(f"\nğŸ“¢ {agent_name} çš„è¯„ä¼°:")
            print(f"{response}")
            print("-" * 40)
            # é¢å¤–æ‰“å°è§£æåçš„ç»“æ„åŒ–è¦ç‚¹ä¸è¯æ®ï¼Œä¾¿äºæ ¸å¯¹åŸå› ä¸å¼•ç”¨
            try:
                print("ğŸ” ç»“æ„åŒ–è¦ç‚¹:")
                print(f"CLAIM: {structured.get('claim','')}")
                ev = structured.get('evidence','')
                if ev:
                    print("EVIDENCE:")
                    print(ev)
            except Exception:
                pass
            time.sleep(2)  # é¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
    
        # æ¯è½®ç»“æŸåï¼šæ›´æ–°æƒé‡ä¸æ—©åœåˆ¤æ®ï¼ˆä½äºè½®æ¬¡å¾ªç¯å†…ï¼‰
        try:
            current_structs = [agents_structured[i][round_idx] for i in range(agents)]
        except Exception:
            current_structs = []
        if current_structs:
            agent_weights = update_agent_weights(agent_weights, current_structs, alpha=1.0, beta=1.0)
            weights_history.append(agent_weights)
        if round_idx > 0 and current_structs:
            prev_text = " ".join([agents_structured[i][round_idx-1].get('summary','') for i in range(agents)])
            curr_text = " ".join([s.get('summary','') for s in current_structs])
            sim = summary_similarity(prev_text, curr_text)
            if sim > 0.92:
                print(f"â¹ï¸ æ—©åœ: ç¬¬{round_idx+1}è½®ä¸ä¸Šä¸€è½®ç›¸ä¼¼åº¦ {sim:.2f} è¶…è¿‡é˜ˆå€¼ 0.92")
                break

    # ç”Ÿæˆç»¼åˆè¯„åˆ†æŠ¥å‘Š
    if "mission_info" not in flight_data:
        flight_data["mission_info"] = {"duration_minutes": 45}
    scoring_report = generate_scoring_report(flight_data, scores, weighted_scores, expert_scorings)
    
    # ä¿å­˜è¯„ä¼°ç»“æœ
    evaluation_result = {
        "question": DEBATE_QUESTION,
        "flight_data": flight_data,
        "expert_roles": agent_names,
        "expert_evaluations": agents_responses,
        "structured_evaluations": agents_structured,
        "debate_weights_history": weights_history,
        "scoring_report": scoring_report,
        "model": "glm-4.6",
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    
    with open("drone_swarm_evaluation_result.json", "w", encoding="utf-8") as f:
        json.dump(evaluation_result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ— äººæœºé›†ç¾¤è¯„ä¼°å®Œæˆï¼")
    print("ğŸ“„ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ° drone_swarm_evaluation_result.json")
    print("ğŸ“„ é£è¡Œæ•°æ®å·²ä¿å­˜åˆ° drone_flight_data.json")
    
    # æ˜¾ç¤ºè¯„åˆ†æŠ¥å‘Šæ‘˜è¦
    print(f"\nğŸ“Š ç»¼åˆè¯„åˆ†æŠ¥å‘Š:")
    print(f"  - æ€»ä½“è¯„åˆ†: {scoring_report['evaluation_summary']['total_score']} ({scoring_report['evaluation_summary']['grade']})")
    for category, data in scoring_report['category_scores'].items():
        print(f"  - {data['name']}: {data['score']} ({data['grade']})")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š è¯„ä¼°ç»Ÿè®¡:")
    print(f"  - ä½¿ç”¨æ¨¡å‹: GLM-4.6")
    print(f"  - å‚ä¸ä¸“å®¶: {agents} ä½")
    print(f"  - è¯„ä¼°è½®æ¬¡: {rounds} è½®")
    print(f"  - æ€»APIè°ƒç”¨æ¬¡æ•°: {agents * rounds} æ¬¡")
    print(f"  - æ— äººæœºæ•°é‡: {flight_data['drone_count']} æ¶")
    print(f"  - é£è¡Œæ—¶é•¿: {flight_data['flight_duration']}")
    print(f"  - é›†ç¾¤è¡¨ç°: ç¨³å®šæ€§{flight_data['swarm_metrics']['formation_stability']}%, å®Œæˆç‡{flight_data['swarm_metrics']['task_completion_rate']}%")
    agents_responses = [[] for _ in range(agents)]
    agents_structured = [[] for _ in range(agents)]
    agent_weights = [1.0 / agents] * agents
    weights_history = []
    
    print(f"\nğŸ¤– æ™ºè°±GLM-4.6 æ— äººæœºé›†ç¾¤è¯„ä¼°ç³»ç»Ÿ")
    print(f"è¾©è®ºé—®é¢˜: {DEBATE_QUESTION}\n")
    
    # æ˜¾ç¤ºé£è¡Œæ•°æ®æ‘˜è¦
    print("ğŸ“Š é£è¡Œæ•°æ®æ‘˜è¦:")
    print(f"  - ä»»åŠ¡ID: {flight_data['mission_id']}")
    print(f"  - ä»»åŠ¡ç±»å‹: {flight_data['mission_type']}")
    print(f"  - æ— äººæœºæ•°é‡: {flight_data['drone_count']} æ¶")
    print(f"  - é£è¡Œæ—¶é•¿: {flight_data['flight_duration']}")
    print(f"  - é›†ç¾¤ç¨³å®šæ€§: {'N/A(å•æœº)' if flight_data['drone_count'] <= 1 else str(flight_data['swarm_metrics']['formation_stability']) + '%'}")
    print(f"  - ä»»åŠ¡å®Œæˆç‡: {'N/A(å•æœº)' if flight_data['drone_count'] <= 1 else str(flight_data['swarm_metrics']['task_completion_rate']) + '%'}")
    
    print("\nå‚ä¸è¯„ä¼°çš„ä¸“å®¶:")
    for i, role in enumerate(agent_roles):
        print(f"  ä¸“å®¶ {i+1}: {role}")
    print("\n" + "="*60)
    
    # ç”Ÿæˆé£è¡Œæ•°æ®æ‘˜è¦
    swarm_stab_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['formation_stability']}%"
    comm_rate_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['communication_success_rate']}%"
    task_comp_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['task_completion_rate']}%"
    avoid_events_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['collision_avoidance_events']} æ¬¡"
    coord_delay_str = "N/A(å•æœº)" if flight_data['drone_count'] <= 1 else f"{flight_data['swarm_metrics']['coordination_delay_avg']} ms"
    flight_summary = f"""
    åŸºäºä»¥ä¸‹æ— äººæœºé›†ç¾¤é£è¡Œæ•°æ®è¿›è¡Œåˆ†æï¼š
    - ä»»åŠ¡ç±»å‹ï¼š{flight_data['mission_type']}
    - æ— äººæœºæ•°é‡ï¼š{flight_data['drone_count']} æ¶
    - é£è¡Œæ—¶é•¿ï¼š{flight_data['flight_duration']}
    - é›†ç¾¤ç¨³å®šæ€§ï¼š{swarm_stab_str}
    - é€šä¿¡æˆåŠŸç‡ï¼š{comm_rate_str}
    - ä»»åŠ¡å®Œæˆç‡ï¼š{task_comp_str}
    - é¿ç¢°äº‹ä»¶ï¼š{avoid_events_str}
    - å¹³å‡åè°ƒå»¶è¿Ÿï¼š{coord_delay_str}"""
    
    # æ›´æ–°æ™ºèƒ½ä½“å¾ªç¯ä»¥ä½¿ç”¨æ–°çš„AGENTSå­—å…¸
    agent_names = list(AGENTS.keys())
    
    # ç”Ÿæˆè‡ªåŠ¨è¯„åˆ†
    print("æ­£åœ¨è®¡ç®—é£è¡Œæ•°æ®è¯„åˆ†...")
    scores = calculate_flight_scores(flight_data)
    weighted_scores = calculate_weighted_scores(scores)
    
    # ä¸ºLLMç”Ÿæˆç´§å‡‘è½¨è¿¹è¯æ®DSL
    traj_summary = summarize_trajectory_for_llm(flight_data)
    evidence_text = format_llm_dsl(traj_summary, scores=scores)
    try:
        attn = compute_traj_attention(flight_data.get("drones", [{}])[0].get("trajectory", []))
        evidence_text = evidence_text + "\n" + build_attn_dsl_block(flight_data.get("drones", [{}])[0].get("trajectory", []), attn)
        print("ğŸ§ª å·²ç”Ÿæˆè½¨è¿¹æ‘˜è¦DSL(å·²æ³¨å…¥åˆ°æç¤º): META/SEG/EVENT/WAYPTS/SCORES/ATTN")
    except Exception:
        print("âš ï¸ æ³¨æ„åŠ›æ‘˜è¦æ„å»ºå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹DSL")
    # æ‰“å°æŠ½è±¡ç»“æœï¼šJSONä¸DSL
    print("\n====== è½¨è¿¹æ‘˜è¦(JSON) ======")
    print(json.dumps(traj_summary, ensure_ascii=False, indent=2))
    print("\n====== è½¨è¿¹æ‘˜è¦(DSL) ======")
    print(evidence_text)
    print("="*60)
    
    # ç”Ÿæˆä¸“å®¶è¯„åˆ†
    expert_scorings = []
    for agent_name in agent_names:
        expert_scoring = generate_expert_scoring(agent_name, flight_data, scores)
        expert_scorings.append(expert_scoring)
    
    print(f"è‡ªåŠ¨è¯„åˆ†å®Œæˆï¼Œæ€»åˆ†: {weighted_scores['total_score']:.2f}")
    
    # è¿›è¡Œè¾©è®º
    for round_idx in range(rounds):
        print(f"\nğŸ”¥ ç¬¬ {round_idx+1} è½®è¯„ä¼°")
        print("-" * 40)
        
        for agent_idx in range(agents):
            agent_name = agent_names[agent_idx]
            agent_info = AGENTS[agent_name]
            
            print(f"\nğŸ’­ {agent_name} æ­£åœ¨åˆ†æ...")
            
            # æ„å»ºæç¤ºï¼ŒåŒ…å«é£è¡Œæ•°æ®å’Œè¯„åˆ†
            if round_idx == 0:
                # ç¬¬ä¸€è½®ï¼šåŸºäºé£è¡Œæ•°æ®å’Œè‡ªåŠ¨è¯„åˆ†è¿›è¡Œåˆ†æ
                prompt = structured_prompt_first_round(
                    agent_info,
                    flight_summary,
                    weighted_scores,
                    expert_scorings[agent_idx],
                    DEBATE_QUESTION,
                    evidence_text=evidence_text,
                )
            else:
                # åç»­è½®æ¬¡ï¼Œè€ƒè™‘å…¶ä»–ä¸“å®¶çš„åˆ†æ
                last_round_responses = [agents_responses[i][round_idx-1] for i in range(agents)]
                prompt = construct_structured_followup(
                    last_round_responses,
                    DEBATE_QUESTION,
                    agent_idx,
                    weighted_scores,
                    expert_scorings[agent_idx],
                    evidence_text=evidence_text,
                )
            
            # è°ƒç”¨APIè·å–å›ç­”
            print("æ­£åœ¨è°ƒç”¨æ™ºè°±GLM-4.6 API...")
            response = call_glm_api(prompt, api_key, agent_info['role'])

            agents_responses[agent_idx].append(response)
            # è§£æç»“æ„åŒ–è¾“å‡ºå¹¶ä¿å­˜
            try:
                structured = parse_structured_response(response)
            except Exception:
                structured = {"summary": "", "confidence": 0.5, "raw": response}
            agents_structured[agent_idx].append(structured)
            
            print(f"\nğŸ“¢ {agent_name} çš„è¯„ä¼°:")
            print(f"{response}")
            print("-" * 40)
            # é¢å¤–æ‰“å°è§£æåçš„ç»“æ„åŒ–è¦ç‚¹ä¸è¯æ®ï¼Œä¾¿äºæ ¸å¯¹åŸå› ä¸å¼•ç”¨
            try:
                print("ğŸ” ç»“æ„åŒ–è¦ç‚¹:")
                print(f"CLAIM: {structured.get('claim','')}")
                ev = structured.get('evidence','')
                if ev:
                    print("EVIDENCE:")
                    print(ev)
            except Exception:
                pass
            time.sleep(2)  # é¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
    
        # æ¯è½®ç»“æŸåï¼šæ›´æ–°æƒé‡ä¸æ—©åœåˆ¤æ®ï¼ˆä½äºè½®æ¬¡å¾ªç¯å†…ï¼‰
        try:
            current_structs = [agents_structured[i][round_idx] for i in range(agents)]
        except Exception:
            current_structs = []
        if current_structs:
            agent_weights = update_agent_weights(agent_weights, current_structs, alpha=1.0, beta=1.0)
            weights_history.append(agent_weights)
        if round_idx > 0 and current_structs:
            prev_text = " ".join([agents_structured[i][round_idx-1].get('summary','') for i in range(agents)])
            curr_text = " ".join([s.get('summary','') for s in current_structs])
            sim = summary_similarity(prev_text, curr_text)
            if sim > 0.92:
                print(f"â¹ï¸ æ—©åœ: ç¬¬{round_idx+1}è½®ä¸ä¸Šä¸€è½®ç›¸ä¼¼åº¦ {sim:.2f} è¶…è¿‡é˜ˆå€¼ 0.92")
                break

    # ç”Ÿæˆç»¼åˆè¯„åˆ†æŠ¥å‘Š
    if "mission_info" not in flight_data:
        flight_data["mission_info"] = {"duration_minutes": 45}
    scoring_report = generate_scoring_report(flight_data, scores, weighted_scores, expert_scorings)
    
    # ä¿å­˜è¯„ä¼°ç»“æœ
    evaluation_result = {
        "question": DEBATE_QUESTION,
        "flight_data": flight_data,
        "expert_roles": agent_names,
        "expert_evaluations": agents_responses,
        "structured_evaluations": agents_structured,
        "debate_weights_history": weights_history,
        "scoring_report": scoring_report,
        "model": "glm-4.6",
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    
    with open("drone_swarm_evaluation_result.json", "w", encoding="utf-8") as f:
        json.dump(evaluation_result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ— äººæœºé›†ç¾¤è¯„ä¼°å®Œæˆï¼")
    print("ğŸ“„ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ° drone_swarm_evaluation_result.json")
    print("ğŸ“„ é£è¡Œæ•°æ®å·²ä¿å­˜åˆ° drone_flight_data.json")
    
    # æ˜¾ç¤ºè¯„åˆ†æŠ¥å‘Šæ‘˜è¦
    print(f"\nğŸ“Š ç»¼åˆè¯„åˆ†æŠ¥å‘Š:")
    print(f"  - æ€»ä½“è¯„åˆ†: {scoring_report['evaluation_summary']['total_score']} ({scoring_report['evaluation_summary']['grade']})")
    for category, data in scoring_report['category_scores'].items():
        print(f"  - {data['name']}: {data['score']} ({data['grade']})")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š è¯„ä¼°ç»Ÿè®¡:")
    print(f"  - ä½¿ç”¨æ¨¡å‹: GLM-4.6")
    print(f"  - å‚ä¸ä¸“å®¶: {agents} ä½")
    print(f"  - è¯„ä¼°è½®æ¬¡: {rounds} è½®")
    print(f"  - æ€»APIè°ƒç”¨æ¬¡æ•°: {agents * rounds} æ¬¡")
    print(f"  - æ— äººæœºæ•°é‡: {flight_data['drone_count']} æ¶")
    print(f"  - é£è¡Œæ—¶é•¿: {flight_data['flight_duration']}")
    print(f"  - é›†ç¾¤è¡¨ç°: ç¨³å®šæ€§{flight_data['swarm_metrics']['formation_stability']}%, å®Œæˆç‡{flight_data['swarm_metrics']['task_completion_rate']}%")


if __name__ == "__main__":
        main()